---
title: "splicing paper"
format: html
editor: visual
---

# Describing the APC model

## Algorithm

All possible combinations (APC) of exons and introns are generated from a given DNA sequence. Introns are gathered based only on canonical donor and acceptor sites. A modified backtracking algorithm is used to generate only valid combinations of introns (isoforms), for example introns that overlap would not be considered. This reduces the search space. **Need graph showing algorithm performance**

## Smallgenes

Due to the inefficiency of generating almost every possible isoform, our test data set needs to be limited in order to reduce the search space. Here we use a small genes data set, with the following constraints.

## Isoform Scoring

Each isoform is scored using 3 probabilistic components: a position weight matrix for donor and acceptor sites, an exon and intron length distribution, and kmer model for exon and intron sequences.

### PWM

The quality of donor and acceptor sites are evaluated using a position weight matrix (PWM). PWMs that cover the length of a specific motif give insight into the prevalence of each nucleotide base at a given position. Training sequences are gathered from the entire worm genome, as opposed to only the smallgenes dataset. This ensures that PWMs are not overtuned for smaller genes, and splice site quality can be more in line with the majority of sites. Splice site quality is evaluated using a Chi square test (Xia, 2012). **PWM equations are also from this paper** For

A position probability matrix is first computed by summing all occurrences of a nucleotide i (either A, C, G, or T) at each position j.

https://www.bioconductor.org/packages/release/bioc/vignettes/universalmotif/inst/doc/IntroductionToSequenceMotifs.pdf

$$ P_{ij} = \sum_{j=1}^L C_i/L $$

Frequencies are then converted to scores using a log odds ratio, where $P_{ij}$ is the frequency of nucleotide $i$ at position $j$, and $P_i$ is the background frequency of that nucleotide (0.25). If $P_{ij}$ is 0, -100 is returned.

$$PWM_{ij} = log_2(p_{ij}/p_i)$$ https://www.sciencedirect.com/topics/medicine-and-dentistry/position-weight-matrix According to this, Position Specific Scoring Matrix is the same as a PWM.

Why do we used 5 bases for donor, 6 for acceptor?

Papers in support of PWM: Methods to define and locate patterns of motifs in sequences, Rodger Staden, 1988 Identification of sequence pattersn, motifs and domains, Michael Gribskov, 2019, Encyclopedia of bioinformatics and computational biology

Info on stats is from Xia, 2012. The minimum length of an intron we consider is 35. So for the chi square test, use a 'donor' site length of 17 and 'acceptor' site length of 18 and see where the frequency stops being significantly different from the background.

https://www.simplilearn.com/tutorials/statistics-tutorial/chi-square-test#chisquare_test_formula

```{r}
library(dplyr)
```


```{r}
# this is the same as pwmtest.py in isoforms
obs <- c(1462, 601, 5244, 1342)
obs <- c(3000, 1500, 1500, 3000)
exp <- c(0.3208, 0.1786, 0.1762, 0.3244)
chisq.test(obs, p=exp)
```

use lintr to check for style

Maybe just use the chi square statistic
```{r}
d <- read.csv("donor_counts.csv", header = FALSE)
a <- read.csv("acceptor_counts.csv", header = FALSE)

dcounts <- d %>% slice(-1)
acounts <- a %>% slice(-1)

dfreqs <- as.numeric(slice(d, 1))
afreqs <- as.numeric(slice(a, 1))

dnums <- lapply(split(dcounts, seq_len(nrow(dcounts))), function(x) as.numeric(x))
anums <- lapply(split(acounts, seq_len(nrow(acounts))), function(x) as.numeric(x))

# d and a freqs are the same
dc <- lapply(dnums, function(x) chisq.test(x, p=dfreqs))
ac <- lapply(anums, function(x) chisq.test(x, p=afreqs))

dres <- dcounts
ares <- acounts

dstat <- lapply(dc, function(x) x$statistic)
astat <- lapply(ac, function(x) x$statistic)

dres$chi_stat <- dstat
ares$chi_stat <- astat
```


```{r}
data <- read.csv("donor_counts.csv", header = FALSE)
counts <- data %>% slice(-1)
freqs <- as.numeric(slice(data, 1))
nums <- lapply(split(counts, seq_len(nrow(counts))), function(x) as.numeric(x))

ctests <- lapply(nums, function(x) chisq.test(x, p=freqs))

results <- counts

stat <- lapply(ctests, function(x) x$statistic)
pval <- lapply(ctests, function(x) x$p.value)

# returns true
# identical(nums[[12]], c(2450, 1080, 1596, 3523))
# pval not consistent/correct
#results$pval <- pval
results$stat <- stat
```

instead of chi square, what does manhattan distance look like?
not good
```{r}
data <- read.csv("donor_counts.csv", header = FALSE)
counts <- data %>% slice(-1)
freqs <- as.numeric(slice(data, 1))
exp <- as.numeric(lapply(freqs, function(x) x * rowSums(data)[2]))
nums <- lapply(split(counts, seq_len(nrow(counts))), function (x) as.numeric(x))

m <- lapply(nums, function(x) x - exp)
md <- lapply(m, function(x) sum(abs(x)))
```


```{r}

library(reticulate)

myenvs=conda_list()
myenvs

# need to install python in the environment
# don't add python from tools > global options
# it conflicts
use_condaenv("Renv")
# can only be run once?
```


```{python}
# need to load conda environment first
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import logomaker
```

```{r}

```

```{python}
introns = "lessintrons.txt"
with open(introns, 'r') as fp:
  for line in fp.readlines():
    print(line)

```

logomaker should allow me to import our pwm instead of calculating the values itself https://logomaker.readthedocs.io/en/latest/examples.html#splice-site-probability-logo

to run python code that is more than one line, need to run the top line first and then the second one.

```{python}
crp_df = logomaker.get_example_matrix(
  'crp_energy_matrix', print_description=False)
crp_df
```

```{python}
crp_df = logomaker.get_example_matrix(
  'crp_energy_matrix', print_description=False)

crp_logo = logomaker.Logo(crp_df, shade_below=.5,
fade_below=.5)

crp_logo.style_spines(visible=False)
crp_logo.style_spines(spines=['left', 'bottom'], visible=True)
crp_logo.style_xticks(rotation=90, fmt='%d', anchor=0)

crp_logo.ax.set_ylabel("ylabel", labelpad=-1)
crp_logo.ax.xaxis.set_ticks_position('none')
crp_logo.ax.xaxis.set_tick_params(pad=-1)

# it works, but not sure how
# logomaker is creating a plt object? but not explicitly named
plt.show()
```

# will probably need to reformat things into csvs for R

```{r}
nuc <- c("A", "C", "G", "T")
p1 <- c(0, 0, 1, 0)
p2 <- c(0, 0, 0, 1)
p3 <- c(0.6, 0, 0.2, 0.2)
p4 <- c(0.7, 0, 0.1, 0.2)
p5 <- c(0.1, 0, 0.8, 0.1)

pwm <- data.frame(p1, p2, p3, p4, p5) %>% 
  t() %>% 
  tibble::as_tibble() %>% 
  as.data.frame() %>% 
  setNames(nuc) 
 

```

```{python}
test_logo = logomaker.Logo(r.pwm, shade_below=.5,
fade_below=.5)

plt.show()

```

How is the intron frequency calculated? See modelbuilder line 78 len(introns) / exon sum Total number of introns over total number of exon sequences Example with actual numbers: 1570 introns in the smallgenes dataset 489418 total number of exon bases inf = 1570/489418 = 0.00320...

Length model

The length of an intron

Create histogram of distances https://www.datacamp.com/tutorial/make-histogram-ggplot2

```{r}
mdists <- read.csv("/home/carl/Code/isoforms/APCanalysis/cdist_sorted.csv", header = FALSE)

library(ggplot2)
library(dplyr)
library (multcompView)

head(mdists)
```

```{r}
dstats <- mdists %>% 
  summarize(mean_dist = mean(V2), median_dist = median(V2))

ggplot(data = mdists, aes(x = V2)) +
  geom_histogram(bins = 100) +
  geom_vline(aes(xintercept = mean_dist), dstats, color = "red") +
  #geom_vline(aes(xintercept = median_dist), dstats, color = "green") +
  #geom_density(color = "blue") +
  labs(x = "Manhattan Distance", y = "Counts")
```

correlation between intron length and distance, intron count and distance? intron count is independent variable x axis intron count y axis is all the manhattan distances, each one gets a single point on the graph will the points cluster? or not cluster? if they do cluster, they do correlate make a box plot, can do pairwise comparison and a linear regression also do MD vs avg intron length

BLAST has a probability model...95 percent of things are predicted from being different

use the bli algorithm to compute all possible isoforms compare bli to apc

```{r}
mdists$introns <- sub("ch.(\\d+)_.*", "\\1", mdists$V1)

ggplot(mdists, aes(x = introns, y = V2)) + geom_point() +
  geom_smooth(method=lm, color="red") +
  labs(y = "Manhattan Distance")
```

```{r}

ggplot(mdists, aes(x = V3, y = V2)) + geom_point() +
  geom_smooth(method=lm, color="red")

```

```{r}
# violin plot
p <- ggplot(mdists, aes(x=introns, y=V2)) + 
  geom_violin() + stat_summary(fun.y=mean, geom="point", shape=23, size=2) + geom_boxplot(width=0.1)

p

# http://vassarstats.net/textbook/ch14pt2.html
# https://courses.lumenlearning.com/introstats1/chapter/the-f-distribution-and-the-f-ratio/
```
The more introns we have, the distances get smaller because there are more introns to even out bad ones. Manhattan distance is not good at ranking genes, does not consider if single intron is bad.
Use CHERBYSEV distance to find the genes with the worst intron.
Optiso with CHERB (D1) compare DTC and D1, Cartesian, Kulback
Need fig to show different distances don't really matter, "worst 10% will be the same"
saw online that you can use a heatmap to represent statistical differences between pairs, so one cube is one comparisson

See this for distances:
# identical(nums[[12]], c(2450, 1080, 1596, 3523))

Venn diagram for comparing different distance equations? But hen need a hard cutoff


```{r}
library(multcompView)

set.seed(1)
treatment <- rep(c("A", "B", "C", "D", "E"), each=20)
value=c(sample(2:5, 20, replace=T), sample(6:10, 20, replace=T), sample(1:7, 20, replace=T), sample(3:10, 20, replace=T), sample(10:20, 20, replace=T))
data=data.frame(treatment, value)

model=lm(data$value ~ data$treatment)
ANOVA=aov(model)
```

<https://bookdown.org/steve_midway/DAR/understanding-anova-in-r.html>

```{r}
m = lm(mdists$V2 ~ mdists$introns)
A = aov(m)

TUKEY <- TukeyHSD(x=A, 'mdists$introns', conf.level=0.95)

plot(TUKEY, las=1, col="brown")
```

none of the groups are significantly different from another https://statisticsbyjim.com/anova/post-hoc-tests-anova/

```{r}
TUKEY$`mdists$introns`
```

```{r}
whatdis <- TUKEY$`mdists$introns`
```

NEED TO DO Genome stats-how many genes are there for each intron count? Is 4 introns good enough for APC? Average structure of gene in wormbase

Next let's do a test without the intron cost

What are the distribution of weights?

```{r}
weights <- read.csv("/home/carl/Code/isoforms/results_optiso2.csv", skip=1)

summary(weights)
```

```{r}
wt <- t(weights) %>% 
  

```

Transcripts on WB have varrying support for each intron. What is that variation? In a single transcript, intron counts should be the same. But what is the actual manhattan distance within a transcript? All pairwise comparisons between introns in a single transcript? Compare introns 1, 2, 3, 4... 1/2 ratio difference? Expected deviation? Expected manhattan distance? Compare intron space where all are 1:1:1:1 only introns that match the canonical isoform Not raw counts instead ratios, 0.25 vs 0.35? Do on all genes and all transcripts Ratio of transcript distribution

lookat datacore2024/genome_celegans for the code

do man u whit test on intron distributions
https://www.r-tutor.com/elementary-statistics/non-parametric-methods/mann-whitney-wilcoxon-test
```{r}
library(tidyvers)
library(tidyr)

ifreqs <- read.csv("intron_frequencies.csv")



wres <- ifreqs %>% 
  group_by(gene_id) %>% 
  summarise(
    pval = wilcox.test(apc, wb, paired = TRUE)$p.value,
    stat = wilcox.test(apc, wb, paired = TRUE)$statistic  
  )


ifreqs %>% wilcox.test(apc ~ wb, paired=TRUE)
  
# results not the same individually

# test on subset
# sub <- ifreqs %>% filter(gene_id == "2_325")
# wilcox.test(sub$apc, sub$wb)
# for 2_325, should get W = 3454, p < 2.2e-16

# i didn't get all the intron freqs for one gene

#wilcox.test(ifreqs$apc, ifreqs$wb)
```

```{r}
v1 <- c("g1", 0.2, 0.1)
v2 <- c("g1", 0.3, 0.4)
v3 <- c("g2", 0.1, 0.5)
v4 <- c("g2", 0.3, 0.6)
test <- data.frame(rbind(v1, v2, v3, v4))
test$X2 <- as.numeric(test$X2)
test$X3 <- as.numeric(test$X3)

result <- test %>% 
  group_by(X1) %>% 
  summarise(
    p = wilcox.test(X2, X3, paired = TRUE)$p.value,
    s = wilcox.test(X2, X3, paired = TRUE)$statistic
  )
```
https://www.geeksforgeeks.org/how-to-merge-two-dataframes-in-r/
```{r}
t1 <- data.frame(
    cbind(rep('g1', 10), 
    (sample.int(11, size=10, replace=TRUE)-1)/100,
    (sample.int(11, size=10, replace=TRUE)-1)/100)
  )
t2 <- data.frame(
    cbind(rep('g2', 10), 
    (sample.int(11, size=10, replace=TRUE)-1)/100,
    (sample.int(11, size=10, replace=TRUE)-1)/100)
  )

t <- rbind(t1, t2)
t$X2 <- as.numeric(t$X2)
t$X3 <- as.numeric(t$X3)

result <- t %>% 
  group_by(X1) %>% 
  summarise(
    p = wilcox.test(X2, X3, paired = TRUE, exact = FALSE)$p.value,
    s = wilcox.test(X2, X3, paired = TRUE, exact = FALSE)$statistic
  )
```
make sure all the parameters are the same
results are the same now
d <- t[t$X1 == 'g1',]
wilcox.test(d$X2, d$X3, paired = TRUE, exact = FALSE)
```{r}
tg <- ifreqs[ifreqs$gene_id == '2_325',]
sum(tg$apc)
sum(tg$wb)
```









